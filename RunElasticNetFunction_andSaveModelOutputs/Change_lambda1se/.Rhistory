Ohio_Label_Training,
alpha = 0.5,
family = "binomial" , standardize = T)
## I. Probability of Train data
## Computing the probability score on the training data using the model
Validating_withtrain <- predict(My_experimental_model,
s = My_experimental_model$lambda.1se,
type = "response",
newx = as.matrix(Exp_Measures_Training))
Validating_withtrain <- as.numeric(format(Validating_withtrain, scientific = F))
## Converting the prob score into classification using the optimal threshold
ROC_train <- roc(ifelse(Group_Train == "SLI", 0, 1), Validating_withtrain)
threshold_experimental <<- coords(ROC_train, x="best")
Ex_Final_predict_Train <- ifelse(Validating_withtrain < threshold_experimental[[1]], 0, 1)
## Saving ENLR prediction scores along with train participant's experimental measures
Experimentaldata_withProb_Train <<- data.frame(Id_train, Validating_withtrain, Ex_Final_predict_Train, Ohio_Label_Training,
Group_Train, Comp_zscore_Train, Sex_Train, Age_Train, Exp_Measures_Training)
names(Experimentaldata_withProb_Train) <<- c("ID","Exp_Model_ProbScore", "Exp_Prediction", "Ohio_Label", "Group", "Comp_zscore",
"Sex", "Age", names(Exp_Measures_Training))}
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- read_excel(find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx"))
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/...
RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
pathname
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- read_excel(find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx"))
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/
RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
pathname
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- read_excel(find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx"))
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
class(pathname)
length(pathname)
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- read_excel(find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx"))
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
Function_IterativelySaves_ModelOutput_3 <- function(data, Num_of_iteration, pathname){
## Installing necessary packages and groundhog them
install.packages(setdiff(c("groundhog", "easypackages", "glmnet", "readxl", "pROC", "openxlsx"),
rownames(installed.packages())))
library("groundhog")
pkgs <- c("glmnet", "readxl", "pROC", "writexl", "openxlsx")
groundhog.library(pkgs, "2024-04-15")
## Loading the data and pulling out dependent and independent variables
Ohio_data <<- read_excel(data)
Experimental_Measures <-
data.frame(Ohio_data[,36:68], Ohio_data[,70:76],
Ohio_data[,78:85], Ohio_data[,88:94],
Ohio_data[,96:107], Ohio_data[,109: 112])
#View(Experimental_Measures)
## Removing participants with missing values from exp data as well as from other
## relevant features of the data (age, sex, id, comp-score, etc).
Missing_Mat <- which(is.na(Experimental_Measures), arr.ind = T)
Experimental_Measures_final <<- na.omit(Experimental_Measures)
Ohio_Label <<- Ohio_data$SLI[-Missing_Mat[, 1]]
Group <<- Ohio_data$group[-Missing_Mat[, 1]]
Sex <<- Ohio_data$sex[-Missing_Mat[, 1]]
Age <<- as.integer(Ohio_data$at_mo_at_test/12)[-Missing_Mat[, 1]]
ID <<- Ohio_data$id[-Missing_Mat[, 1]]
Comp_zscore <<- Ohio_data$composite_z_score[-Missing_Mat[, 1]]
## Select different sample combinations with sample without replacement
Num_of_iteration <- Num_of_iteration
# My_Sample <<- lapply(1:Num_of_iteration, function(i) {
#               set.seed(1)
#               sample(1:nrow(Experimental_Measures_final))})
set.seed(1334)                                                          #                                               replace = F))
My_Sample <<- lapply(1:Num_of_iteration, function(i) sample(nrow(Experimental_Measures_final),
replace = F))
#
## Modeling across 200 reshuffled data to generalize model's behavior
alpha <- 0.5
Performance_training <- c()
Performance_Both <- data.frame()
Ls_Models_Output_Train <- list()
Features <- list()
Coefficients <- list()
FeatureandCoefficients <- list()
## Iteratively running the function that creates the models and saving model output
for (i in 1:Num_of_iteration){
Sample = unlist(My_Sample[i])
ElasticNetFunctions_InternalCode_2(alphA = alpha,
partition_percentage = 1, Sample)
##Grabbing probability scores including other relevant features of the participants
Model_iteration <- paste("Model_iteration", i, sep="")
Ls_Models_Output_Train[[Model_iteration]] <- Experimentaldata_withProb_Train
## Grabbing features along with their coefficients
Features[[i]] <-
names(as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se))[as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se)) != 0, ])
Coefficients[[i]] <-
as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se))[as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se))!=0]
FeatureandCoefficients[[Model_iteration]] <-
data.frame(Features = Features[[i]], Coefficients = Coefficients[[i]])
print(i)
}
Ls_Models_Output_Train <<- Ls_Models_Output_Train
## Saving model outputs and performance in Excel
write_xlsx(Performance, "ModelsPerformance_200iterations_Try2.xlsx")
openxlsx::write.xlsx(Ls_Models_Output_Train,
file = paste(pathname, '/ModelsOutputTrain_200iterations.xlsx', sep = ""))
openxlsx::write.xlsx(FeatureandCoefficients,
file = paste(pathname, '/FeatureandCoefficients_200iterations.xlsx', sep = ""))
}
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
Function_IterativelySaves_ModelOutput_3 <- function(data, Num_of_iteration, pathname){
## Installing necessary packages and groundhog them
install.packages(setdiff(c("groundhog", "easypackages", "glmnet", "readxl", "pROC", "openxlsx"),
rownames(installed.packages())))
library("groundhog")
pkgs <- c("glmnet", "readxl", "pROC", "writexl", "openxlsx")
groundhog.library(pkgs, "2024-04-15")
## Loading the data and pulling out dependent and independent variables
Ohio_data <<- read_excel(data)
Experimental_Measures <-
data.frame(Ohio_data[,36:68], Ohio_data[,70:76],
Ohio_data[,78:85], Ohio_data[,88:94],
Ohio_data[,96:107], Ohio_data[,109: 112])
#View(Experimental_Measures)
## Removing participants with missing values from exp data as well as from other
## relevant features of the data (age, sex, id, comp-score, etc).
Missing_Mat <- which(is.na(Experimental_Measures), arr.ind = T)
Experimental_Measures_final <<- na.omit(Experimental_Measures)
Ohio_Label <<- Ohio_data$SLI[-Missing_Mat[, 1]]
Group <<- Ohio_data$group[-Missing_Mat[, 1]]
Sex <<- Ohio_data$sex[-Missing_Mat[, 1]]
Age <<- as.integer(Ohio_data$at_mo_at_test/12)[-Missing_Mat[, 1]]
ID <<- Ohio_data$id[-Missing_Mat[, 1]]
Comp_zscore <<- Ohio_data$composite_z_score[-Missing_Mat[, 1]]
## Select different sample combinations with sample without replacement
Num_of_iteration <- Num_of_iteration
# My_Sample <<- lapply(1:Num_of_iteration, function(i) {
#               set.seed(1)
#               sample(1:nrow(Experimental_Measures_final))})
set.seed(1334)                                                          #                                               replace = F))
My_Sample <<- lapply(1:Num_of_iteration, function(i) sample(nrow(Experimental_Measures_final),
replace = F))
#
## Modeling across 200 reshuffled data to generalize model's behavior
alpha <- 0.5
#Performance_training <- c()
#Performance_Both <- data.frame()
Ls_Models_Output_Train <- list()
Features <- list()
Coefficients <- list()
FeatureandCoefficients <- list()
## Iteratively running the function that creates the models and saving model output
for (i in 1:Num_of_iteration){
Sample = unlist(My_Sample[i])
ElasticNetFunctions_InternalCode_2(alphA = alpha,
partition_percentage = 1, Sample)
##Grabbing probability scores including other relevant features of the participants
Model_iteration <- paste("Model_iteration", i, sep="")
Ls_Models_Output_Train[[Model_iteration]] <- Experimentaldata_withProb_Train
## Grabbing features along with their coefficients
Features[[i]] <-
names(as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se))[as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se)) != 0, ])
Coefficients[[i]] <-
as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se))[as.matrix(coef(My_experimental_model, s = My_experimental_model$lambda.1se))!=0]
FeatureandCoefficients[[Model_iteration]] <-
data.frame(Features = Features[[i]], Coefficients = Coefficients[[i]])
print(i)
}
Ls_Models_Output_Train <<- Ls_Models_Output_Train
## Saving model outputs and performance in Excel
#write_xlsx(Performance, "ModelsPerformance_200iterations_Try2.xlsx")
openxlsx::write.xlsx(Ls_Models_Output_Train,
file = paste(pathname, '/ModelsOutputTrain_200iterations.xlsx', sep = ""))
openxlsx::write.xlsx(FeatureandCoefficients,
file = paste(pathname, '/FeatureandCoefficients_200iterations.xlsx', sep = ""))
}
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/RunningModel_savingCrossValidated_Info/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
getwd()
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 2
pathname = "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/Change_lambda1se"
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
setwd("/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se")
getwd()
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 2
pathname = '/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/Change_lambda1se/'
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 2
pathname = '/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/Change_lambda1se'
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
getwd()
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 2
pathname = '/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren//RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se'
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
## Specify the location (path and directory of the file) of the Montgomery database.
library(easypackages)
libraries("readxl", "ggplot2", "ggalt", "openxlsx", "writexl", "rio",
"tidyverse", "pROC")
library(here)
find_file <- function(filename) {
path <- list.files(path = here::here(),
pattern = filename,
recursive = TRUE,
full.names = TRUE)
if (length(path) == 0) stop(paste("File", filename, "not found!"))
if (length(path) > 1) warning("Multiple files found. Using the first one.")
return(path[1])
}
data <- find_file("Master9_Mtch_117x2_v13_with_PSs_1-1-18_Corrected634ID_zscore.xlsx")
## How many iterations of models do we need/want to run?
Num_of_iteration <- 200
pathname = '/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren//RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se'
## Grabbing models output for the number of iterations using the model function
Function_IterativelySaves_ModelOutput_3(data, Num_of_iteration, pathname)
rm(list = ls())
install.packages("readxl")
install.packages("dplyr")
install.packages("purrr") # useful for iterating over sheets
library(readxl)
library(purrr)
library(dplyr)
#file1_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/ModelsOutputTrain_200iterations.xlsx"
#file2_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se/ModelsOutputTrain_200iterations_Lambda1se.xlsx"
file1_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/FeatureandCoefficients_200iterations.xlsx"
file2_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se/FeatureandCoefficients_200iterations_Lambda1se.xlsx"
# Get sheet names from each file
sheets1 <- excel_sheets(file1_path)
sheets2 <- excel_sheets(file2_path)
install.packages("dplyr")
install.packages("purrr")
install.packages("readxl")
install.packages("readxl")
#install.packages("readxl")
#install.packages("dplyr")
#install.packages("purrr") # useful for iterating over sheets
install.packages(setdiff(c("glmnet", "readxl", "openxlsx", "dplyr", "purrr"),
rownames(installed.packages())))
library(readxl)
library(purrr)
library(dplyr)
#file1_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/ModelsOutputTrain_200iterations.xlsx"
#file2_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se/ModelsOutputTrain_200iterations_Lambda1se.xlsx"
file1_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/FeatureandCoefficients_200iterations.xlsx"
file2_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se/FeatureandCoefficients_200iterations_Lambda1se.xlsx"
# Get sheet names from each file
sheets1 <- excel_sheets(file1_path)
sheets2 <- excel_sheets(file2_path)
# Read all sheets into lists of data frames
excel_data1 <- map(sheets1, ~read_excel(file1_path, sheet = .x))
excel_data2 <- map(sheets2, ~read_excel(file2_path, sheet = .x))
# Assign names to the list elements for easier access (optional but recommended)
names(excel_data1) <- sheets1
names(excel_data2) <- sheets2
if (!identical(sort(sheets1), sort(sheets2))) {
print("Sheet names are different. Files are not identical.")
} else {
print("Sheet names are the same.")
}
if (identical(sort(sheets1), sort(sheets2))) {
all_sheets_match <- TRUE
for (sheet_name in sheets1) {
df1 <- excel_data1[[sheet_name]]
df2 <- excel_data2[[sheet_name]]
# Compare data frames, optionally ignoring row order and/or column order
if (!identical(df1, df2)) { # or use all.equal(df1, df2) for less strict comparison
print(paste("Sheet:", sheet_name, "has differences."))
all_sheets_match <- FALSE
# You can add more detailed comparisons here if needed
# For example:
# diff_result <- all_equal(df1, df2, ignore_row_order = TRUE)
# print(diff_result)
}
}
if (all_sheets_match) {
print("All sheets have the same values.")
} else {
print("Some sheets have different values.")
}
}
#install.packages("readxl")
#install.packages("dplyr")
#install.packages("purrr") # useful for iterating over sheets
install.packages(setdiff(c("glmnet", "readxl", "openxlsx", "dplyr", "purrr"),
rownames(installed.packages())))
library(readxl)
library(purrr)
library(dplyr)
file1_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/ModelsOutputTrain_200iterations.xlsx"
file2_path <- "/Users/susmusharma/Desktop/Classes_Records/First_Year_Paper/R_Codes/New_R_Codes_for_AllChildren/RunElasticNetFunction_andSaveModelOutputs/Change_lambda1se/ModelsOutputTrain_200iterations_Lambda1se.xlsx"
# Get sheet names from each file
sheets1 <- excel_sheets(file1_path)
sheets2 <- excel_sheets(file2_path)
# Read all sheets into lists of data frames
excel_data1 <- map(sheets1, ~read_excel(file1_path, sheet = .x))
excel_data2 <- map(sheets2, ~read_excel(file2_path, sheet = .x))
# Assign names to the list elements for easier access (optional but recommended)
names(excel_data1) <- sheets1
names(excel_data2) <- sheets2
if (!identical(sort(sheets1), sort(sheets2))) {
print("Sheet names are different. Files are not identical.")
} else {
print("Sheet names are the same.")
}
if (identical(sort(sheets1), sort(sheets2))) {
all_sheets_match <- TRUE
for (sheet_name in sheets1) {
df1 <- excel_data1[[sheet_name]]
df2 <- excel_data2[[sheet_name]]
# Compare data frames, optionally ignoring row order and/or column order
if (!identical(df1, df2)) { # or use all.equal(df1, df2) for less strict comparison
print(paste("Sheet:", sheet_name, "has differences."))
all_sheets_match <- FALSE
# You can add more detailed comparisons here if needed
# For example:
# diff_result <- all_equal(df1, df2, ignore_row_order = TRUE)
# print(diff_result)
}
}
if (all_sheets_match) {
print("All sheets have the same values.")
} else {
print("Some sheets have different values.")
}
}
